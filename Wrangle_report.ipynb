{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle_report\n",
    "\n",
    "The data wrangling process consists of three parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to gather three datasets to conduct the analysis.First I imported the twitter-archive-enhanced.csv dataset provided by Udacity using pandas read_csv method.Then I used requests.get() method to download the dataset via the link.Then I created a twitter developer acount to scrape data such as favourite_count, retweet_count,followers_count,favourtes_count and date_time from the twitter account @dog_rates using API for all 5000+ tweets by August 1,2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used sample( ) to take a glimpse of the datasets.Then I used info( ),describe( ),value_counts( ) and isnull( ).sum( ) methods to access the data to view if there are any data quality and data sturctural issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter_archive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Column expanded_urls has missing values.  \n",
    "2. Name columns has invalid values like 'a','an','the' and 'one'.  \n",
    "3. Rating_numerator and rating_denominator have invalidate values.  \n",
    "4. The data type of tweet_id, in_reply_to_status_id,in_reply_to_user_id retweeted_status_id,retweeted_status_user_id should be string instead of number,the data of timestamp should be datetime instead of string.  \n",
    "5. Missing value in name columns should be nan instead of 'None'  \n",
    "6. The source column needs to be cleaned  \n",
    "7. Some entries should be classified as pupper instead of 'None.  \n",
    "8. Drop coulmns that are not for analysis.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inconsistenct caplitalization in the starting letter in columns p1 p2 and p3.\n",
    "2. The columns p1,p2 and p3 should be renamed with more explanatory coulmn names.  \n",
    "3. The data type of p1,p2 and p3 should be category instead of string.  \n",
    "4. There are only 2075 non_null observations in this dataframe.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are only 2330 non-null observations in this dataframe.    \n",
    "2. The data type of datetime should be datetime instead of string and the data type of tweet id should be string instead of float.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data sturctural issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Doggo,floofer,pupper,puppo should be in the same column in the twitter_archive dataframe and convert them to the caterory instead of string.   \n",
    "2. All the replies in the twitter_archive dataframe need to be removed to ensure that every row represents one entry.  \n",
    "3. All the three dataframe should be merged into one dataset.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tMake expanded_url for the missing values by function to add tweet_id after the link  'https://twitter.com/dog_rates/status/â€™. \n",
    "2.\tUse a function to replace those invalid names such as 'a','an' with 'none' if we can't find any name information in the text column\n",
    "3.\tAll the replies need to be removed to ensure that every row represents one entry. if the tweet is a reply, in_reply_to_status_id must be a not null value. Select all the rows with a null value in the in_reply_to_status_id column to get rid of the replies tweets.\n",
    "4. I only conduct analysis on the original tweets,those columns associating with reply or retweet need to be dropped.\n",
    "5.\tConvert the data type of tweet_id to string.Convert the data type of timestamp to datetime.Convert the data type of rating_numerator and rating_denominator to float.\n",
    "6.\tUse value_counts() to check if there are any extreme values in rating_numerator and rating_denominator columns.Define a function to check if these extreme values in the rating_numerator column are consistent with the number in the text column.Correct them if they are not. Convert all the rating_denominator to 10 . Then check if the values in the text column contain any decimals and if there are ,check whether these values are consistent with the decimals in the text columns.Correct them if they are not.\n",
    "7.\tUse Regular Expression to extract the information of the source of the tweets in the source column\n",
    "8.\tUse Regular Expression to obtain the information of the dog stage from the text column and then created a new column for the extracted information and drop doggo,pupper,floofer and puppo columns from the dataset\n",
    "10.\tReplace the missing value in name columns with nan instead of 'None'.\n",
    "11. Store the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tUse str.lower( ) to convert all the columns into lower case.\n",
    "2.\tRename the columns with more explanatory column names.\n",
    "3.\tConvert the datatype of p1,p2 and p3 to category.\n",
    "4.\tMerge the image_prediction into twitter_archive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert the data type of tweet_id to string and convert the data type of date_time to date time.\n",
    "2. Merge the df_json_data to the previous two dataset.\n",
    "3. Store the final data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct the data types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
